{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXy8KdiOoGly"
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "In this assignment, you’ll get hands-on experience coding and training GANs. This assignment is\n",
    "divided into two parts: in the first part, we will implement a specific type of GAN designed to\n",
    "process images, called a Deep Convolutional GAN (DCGAN). We’ll train the DCGAN to generate\n",
    "emojis from samples of random noise. In the second part, we will apply some methods that researchers have suggested to \"stablize\" the training process of GANs and then train our DCGAN again.\n",
    "\n",
    "**Note:** Please attempt this assignment on Google Colab, since that will speed up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "Na6nVHCmoGl0",
    "outputId": "9bed9037-18b5-429b-d78f-6112c62c7e7b"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run these in Colab\n",
    "# %tensorflow_version 1.x\n",
    "# !pip install --upgrade opencv-python==3.4.2.17\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv2D,Activation,BatchNormalization,Conv2DTranspose, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD, RMSProp\n",
    "import os\n",
    "from glob import glob\n",
    "from skimage.io import imread,imshow,imsave\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from keras.preprocessing import image as k_image\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0WYS8n7Ioigi",
    "outputId": "aa7bd030-6cef-471b-ed5d-02ba6782e86e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqmM03ovoGl7"
   },
   "outputs": [],
   "source": [
    "ROLLNUMBER = None\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SHAPE = [64,64]\n",
    "CHANNELS = 3\n",
    "NOISE_DIM = 100\n",
    "EPOCHS = 2500\n",
    "# Use this to prefix all your paths when reading/writing data to drive.\n",
    "BASE_DIR = ''\n",
    "# BASE_DIR = '/content/drive/My Drive/CS437 - Deep Learning/DLAS5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's the link to the emojis dataset: https://drive.google.com/open?id=1WRpE9SwSqguyGrrI9EP6jlHk7f1hoJMo\n",
    "\n",
    "- Here's the link to the full emojis dataset: https://drive.google.com/open?id=1UeIQIbixvapM-TBzngOwDXnHV_vv-MBG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8l9jSjsoGl_"
   },
   "source": [
    "## PART 1: Deep Convolutional GAN (DCGAN)\n",
    "For the first part of this assignment, we will implement a Deep Convolutional GAN (DCGAN).\n",
    "A DCGAN is simply a GAN that uses a convolutional neural network as the discriminator, and\n",
    "a network composed of transposed convolutions as the generator. To implement the DCGAN, we\n",
    "need to specify three things: 1) the generator, 2) the discriminator, and 3) the training procedure.\n",
    "We will develop each of these three components in the following subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WYSmKrooGmA"
   },
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "def sample_noise():\n",
    "    return np.reshape(np.random.randn(NOISE_DIM * BATCH_SIZE),(BATCH_SIZE,NOISE_DIM))\n",
    "\n",
    "def remove_transparency(source, background_color):\n",
    "    source_img = source[:, :, :3]\n",
    "    source_mask = source[:, :, 3]  * (1 / 255.0)\n",
    "    source_mask = np.repeat(source_mask[:, :, np.newaxis], 3, axis=2)\n",
    "    background_mask = 1.0 - source_mask\n",
    "    bg_part = (background_color * (1 / 255.0)) * (background_mask)\n",
    "    source_part = (source_img * (1 / 255.0)) * (source_mask)\n",
    "    return cv2.cvtColor(np.uint8(cv2.addWeighted(bg_part, 255.0, source_part, 255.0, 0.0)),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_data():\n",
    "    base_dir = 'filtered_emojis/*'\n",
    "    train_files = glob(base_dir)\n",
    "    train_images = np.array([cv2.resize(remove_transparency(cv2.imread(f,-1),255),tuple(IMAGE_SHAPE)) for f in train_files])\n",
    "    return train_images\n",
    "\n",
    "def create_image_grid(array, ncols=None):\n",
    "    num_images, cell_h, cell_w, channels = array.shape\n",
    "    if not ncols:\n",
    "        ncols = int(np.sqrt(num_images))\n",
    "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
    "    result = np.zeros((cell_h*nrows, cell_w*ncols, channels), dtype=array.dtype)\n",
    "    for i in range(0, nrows):\n",
    "        for j in range(0, ncols):\n",
    "            result[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w, :] = array[i*ncols+j]\n",
    "\n",
    "    if channels == 1:\n",
    "        result = result.squeeze()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ecGO7IxSoGmD"
   },
   "source": [
    "### Implementing the Discriminator of the DCGAN\n",
    "The discriminator in this DCGAN is a convolutional neural network that has the following architecture:\n",
    "<br>\n",
    "![DCGAN Discriminator](DCGAN_disc.png)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Important points**:\n",
    "- Pass in the following arguments in your Convolutional Layers: padding='same',use_bias=False\n",
    "- After the last convolutional layer, Flatten the output and then add the final dense layer for prediction\n",
    "- Use kernel_size of (4,4), except the last one -- You may change this ((4,4) one) but don't reduce it too much\n",
    "- Reduce the spatial dimension by a factor of 2 after each convolution, except the last one.\n",
    "- Use LeakyRelu and BatchNormalization after each convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lUD4QhIoGmg"
   },
   "source": [
    "Implement the discriminator in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzrtPjwtoGmt"
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLLYL_SwoGm1"
   },
   "source": [
    "### Implementing the generator of DCGAN\n",
    "Now, we will implement the generator of the DCGAN, which consists of a sequence of transpose\n",
    "convolutional layers that progressively upsample the input noise sample to generate a fake image.\n",
    "The generator has the following architecture:\n",
    "<br>\n",
    "![DCGAN Generator](DCGAN_gen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some important points:**\n",
    "- Pass in use_bias=False,padding='same' in your convolutional layers.\n",
    "- All intermediate convolutional layers will have relu activation except the last one, which will have tanh.\n",
    "- All other properties can be inferred from the above diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aZfsZzyoGm2"
   },
   "source": [
    "Implement the generator in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCeSFwVOoGnI"
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLBvnCg9oGnQ"
   },
   "source": [
    "### DCGAN Training Loop\n",
    "Next, you will implement the training loop for the DCGAN. A DCGAN is simply a GAN with a\n",
    "specific type of generator and discriminator; thus, we train it in exactly the same way as a standard\n",
    "GAN. The pseudo-code for the training procedure is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGPb8zLVoGnQ"
   },
   "source": [
    "**Algorithm:**    \n",
    "1. Draw m training examples {x<sup>(1)</sup>,...,x<sup>(m)</sup>} from the data distribution p<sub>data</sub>.\n",
    "2. Draw m noise samples {z<sup>(1)</sup>,...,z<sup>(m)</sup>} from the noise distribution p<sub>z</sub>.    \n",
    "3. Generate fake images from the noise: G(z<sup>(i)</sup>) for i in {1,....,m}.    \n",
    "4. Compute discriminator's loss on real images and fake images batches and then update the parameters.\n",
    "5. Draw m NEW noise samples {z<sup>(1)</sup>,...,z<sup>(m)</sup>} from the noise distribution p<sub>z</sub>.    \n",
    "6. Generate fake images from the noise: G(z<sup>(i)</sup>) for i in {1,....,m}.    \n",
    "7. Freeze the discriminator.\n",
    "8. Compute generator's loss then update the parameters.\n",
    "9. Unfreeze the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqCxtSS9oGnR"
   },
   "source": [
    "Before we move to writing the training loop, we will need to create a \"combined\" model that will attach the discriminator over the generator. This model will be used to train the generator as the discriminator will act as an adversary for the generator and force it to generate realistic images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function below you need to create a model that:\n",
    "- Takes noise z as input (Matching the noise dimensions defined at the top of the notebook)\n",
    "- Gets a fake image generated from the generator using this noise z\n",
    "- \"Freezes\" the discriminator (Setting all layers of the discriminator as untrainable)\n",
    "- Outputs the output of the discriminator based on the input z.\n",
    "\n",
    "Remember to compile the model before returning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPM1oSn3oGnS"
   },
   "outputs": [],
   "source": [
    "def build_gan(gen,disc):    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your training loop in the cell bellow. Some important points to keep in mind:\n",
    "- You need to compile the discriminator after creating an instance using build_discriminator()\n",
    "- Use the provided load_data() function to well... load the data. You can choose between generating Windows or Apple emojis\n",
    "- The entire data will be loaded as it is small enough to fit into memory (Finally no data generators, right?) BUT you still need to loop over the data in batches. Starter code is provided to you.\n",
    "- To train your models, we won't make use of <code>fit</code> instead we will use <code>train_on_batch</code> to train our model over batches. This method will return your model's loss over a particular batch, which you will use to output and store your history of losses.\n",
    "- Additionally, we will be generating samples after some epochs and storing the result on disk. The code is provided to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(generated_images,step,save_at=\"samples/\"):\n",
    "    sample_image = create_image_grid(generated_images)\n",
    "    img = k_image.array_to_img(sample_image)\n",
    "    img.save(os.path.join(BASE_DIR,save_at, 'generated_image_' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqhAFs7eoGnX"
   },
   "outputs": [],
   "source": [
    "def gan_training_loop(intervals=200):\n",
    "    # Setup Models here\n",
    "    X_train = load_data()\n",
    "    total_size = X_train.shape[0]\n",
    "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
    "    all_disc_loss = []\n",
    "    all_gen_loss = []\n",
    "    if total_size % BATCH_SIZE:\n",
    "        indices = indices[:-1]\n",
    "    for e in range(EPOCHS):\n",
    "        progress_bar = Progbar(target=len(indices))\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        for i,index in enumerate(indices):\n",
    "            # Write your code here\n",
    "            if not (e % intervals):\n",
    "                save_samples(generated_imgs,e)     \n",
    "            \n",
    "            disc_loss = None\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "            \n",
    "            # Before training your generator using the combined model, freeze all layers of the discriminator first.\n",
    "            # Unfreeze after your call to train_on_batch\n",
    "            gen_loss = None\n",
    "            epoch_gen_loss.append(gen_loss)\n",
    "            progress_bar.update(i+1)\n",
    "        if not (e%intervals):\n",
    "            # Save weights here\n",
    "            discriminator.save_weights(os.path.join(BASE_DIR,'discriminator'),True)\n",
    "            generator.save_weights(os.path.join(BASE_DIR,'generator'),True)\n",
    "            \n",
    "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
    "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
    "        all_disc_loss.append(avg_epoch_disc_loss)\n",
    "        all_gen_loss.append(avg_epoch_gen_loss)\n",
    "\n",
    "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f\" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
    "    return all_disc_loss,all_gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVg0fxpHoGnf"
   },
   "source": [
    "### Training the GAN\n",
    "We will train a DCGAN to generate fake Apple emojis. 1 epoch should take about 15 seconds on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-I4naFxeoGnf"
   },
   "source": [
    "Train your DCGAN in the below cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Samples and Analysis\n",
    "\n",
    "- Plot your discriminator and generator losses and explain how it represents the MiniMax game in play, and comment on the trends you observe.\n",
    "- Generate random 5 noise samples and their corresponding fake images.\n",
    "- Mention if you observe any failure modes\n",
    "- **BONUS (5%):** Try generating some good samples, and try interpolating the input noise samples (Vector Arithmetic) to see if the results are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(gen_loss,disc_loss):\n",
    "    plt.plot(gen_loss)\n",
    "    plt.plot(disc_loss)\n",
    "    plt.title('GAN Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Generator', 'Discriminator'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Stablizing GANs\n",
    "\n",
    "In the first part, we trained our GAN using the standard methods proposed initially. In this part we will tweak our models and our training loop based on suggestions that deep learning researchers have come up with through their experiences. We will see if we encountered into typical problems faced while training GANs and see if these proposed methods improve our GANs and resolve issuse previously faced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already implemented a GAN based on the recommendations made by Alec Radford, et al. in the 2015 paper titled [“Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.”](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "\n",
    "\n",
    "We have:\n",
    "1. Downsampled using strided convolutions\n",
    "2. Upsampled using strided convolutions\n",
    "3. Used LeakyReLu in our discriminator, and ReLu in the generator and Tanh for the output of the generator.\n",
    "4. Used BatchNormalization in both the discriminator and generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these, we will also make use of some more tips from the aforementioned paper, as well as tips from Soumith Chintala, who is one of the co-authors of the DCGAN paper in his [NIPS presentation](https://www.youtube.com/watch?v=X1mUN6dD8uE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifications in the Models\n",
    "\n",
    "Here are some suggested modifications in the generator and discriminator models:\n",
    "\n",
    "- Use LeakyReLu in BOTH the generator and discriminator\n",
    "- Use Gaussian Weight initialization with mean=0 and std = 0.02. (Use the imported RandomNormal function to get weights and pass it in as the kernel_initializer argument in a convolutional layer)\n",
    "- Use Adam optimizer\n",
    "\n",
    "Make these modifications in your generator and discriminator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Images to the Range [-1,1]\n",
    "We already know that normalizing images improves training for any model. We will scale our images in the range [-1,1] since we are using a tanh activation in our generator. This will make the fake generated images and real images in the same range and will enable our discriminator to learn better.    \n",
    "Implement the following function to normalize a numpy array containing images. **Note:** The images will be in the range [0,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gaussian Latent Space\n",
    "Previously we have been using a uniform distribution to sample a latent space as recommended in the DCGAN paper, but more recently researchers suggest to use a Standard Gaussian distribution to sample the latent space. Modify the <code>sample_noise</code> function to sample fomr a Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Label Smoothing\n",
    "Normally, we use hard labels 1s and 0s to train our GANs. Researchers have suggested to smooth labels and use \"soft\" labels . This is said to have a \"regularizing\" effect on the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Label Smoothing\n",
    "For Real labels, i.e. 1s, we will smooth the labels uniformly between [0.7,1.2]. Use np.random.random for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_real_labels(y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fake Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_fake_labels(y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of these functions later in our training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Discriminator with Real and Fake Images separately\n",
    "Previously we were combining our fake and real images batches and doing one update to our discriminator. Researchers suggest that the best practice is to train our discriminator in two updates, one for the real images and one for the fake images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip some labels randomly while training the Generator\n",
    "Soumith Chintala also suggests that in practice, ocassionally flipping the labels of the generator may help (Swapping Real and Fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Training Loop\n",
    "\n",
    "Incorporate the above mentioned suggestions in your training process. You don't have to apply all of them. See which combination works best for you. Mention the methods you made use of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_training_loop(intervals=200):\n",
    "    # Setup Models here\n",
    "    X_train = load_data()\n",
    "    total_size = X_train.shape[0]\n",
    "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
    "    all_disc_loss = []\n",
    "    all_gen_loss = []\n",
    "    if total_size % BATCH_SIZE:\n",
    "        indices = indices[:-1]\n",
    "    for e in range(EPOCHS):\n",
    "        progress_bar = Progbar(target=len(indices))\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        for i,index in enumerate(indices):\n",
    "            # Write your code here\n",
    "            if not (e % intervals):\n",
    "                save_samples(generated_imgs,e)\n",
    "                \n",
    "            # If you are training the discriminator in two updates, uncomment this\n",
    "            # disc_loss = (disc_fake_loss + disc_real_loss) * 0.5\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "            \n",
    "            progress_bar.update(i+1)\n",
    "        if not (e%intervals):\n",
    "            discriminator.save_weights(os.path.join(BASE_DIR,'discriminator'),True)\n",
    "            generator.save_weights(os.path.join(BASE_DIR,'generator'),True)\n",
    "            \n",
    "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
    "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
    "        all_disc_loss.append(avg_epoch_disc_loss)\n",
    "        all_gen_loss.append(avg_epoch_gen_loss)\n",
    "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f\" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
    "    return all_disc_loss,all_gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis \n",
    "Repeat the above analysis and mention changes you observed in terms of training and quality of fake images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS - 10%\n",
    "The current training set was a subset of the actual emojis dataset. In the filtering process, most inanimate objects were removed and the focus was on front-facing emojis. Train the model over the full dataset or a subset of your choice and repeat the above analysis"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_PA5-EmojiGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
